{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review results\n",
    "This notebook will evaluate predictions against ground truth segmentation masks; contains utils for computing the Dice score and visalizing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from shared_utils import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append(\"../dauphin/image_segmentation/datasets\")\n",
    "from utils import custom_preproc_op\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"220\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#1147a1;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#5dc1ee;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#89c579;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#de6400;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.06666666666666667, 0.2784313725490196, 0.6313725490196078),\n",
       " (0.36470588235294116, 0.7568627450980392, 0.9333333333333333),\n",
       " (0.5372549019607843, 0.7725490196078432, 0.4745098039215686),\n",
       " (0.8705882352941177, 0.39215686274509803, 0.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set color palette\n",
    "colors = ['#1147A1','#5DC1EE','#89C579','#DE6400']\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "sns.color_palette()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data to review - should only need to modify this cell for custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "task = 'acdc' # Task name, should match the task name where data is stored\n",
    "split = 'test' # Data split you want to evaluate (train, val, test)\n",
    "data_path = '../data/'+task+'/'+split # Path to where image data is stored\n",
    "config_file = '../data/'+task+'/config.yaml' # Path to config file for this dataset\n",
    "gt_seg_path = '../data/'+task+'/'+split # Path to where ground truth segmentation masks are stored, typically the same as data_path\n",
    "pred_seg_paths = ['../logs/'+task+'_logs/UNet/gt_train_labels/augment_4/with_consistency_loss/without_uncertainty_thresh/csv_acdc_5-keys_all-slice-per-key_seed-1/seed_1/final_preds/'+split] # Path to where predicted segmentation masks are stored (list); can include more than one path in list to evaluate multiple prediction dirs\n",
    "img_size_r  = 224 # Should be the same as the param used to train seg networks\n",
    "img_size_c  = 224 # Should be the same as the param used to train seg networks\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image keys available: 30\n",
      "Number of keys that also have predictions saved: 30\n",
      "Retreiving image and gt segs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 1212.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 49.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of input, ground truth, and all predicted data: 30 30 [30]\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_data = []\n",
    "gt_data = []\n",
    "pred_data = {pred_name:[] for pred_name in pred_seg_paths} \n",
    "\n",
    "# Get all successful keys, which have an image, gt, and prediction available\n",
    "successful_keys = [('_').join(p.split('/')[-1].split('_')[:-1]) for p in glob.glob(os.path.join(data_path,'*_image*'))]\n",
    "print('Number of image keys available:',len(successful_keys))   \n",
    "for pred_path in pred_seg_paths:\n",
    "    all_pred_keys = [('_').join(p.split('/')[-1].split('_')[:-1]) for p in glob.glob(os.path.join(pred_path,'*_seg*'))]\n",
    "    successful_keys = [i for i in successful_keys if i in all_pred_keys] \n",
    "print('Number of keys that also have predictions saved:',len(successful_keys))\n",
    "  \n",
    "# Save input and gt data\n",
    "print('Retreiving image and gt segs')\n",
    "for key in tqdm(successful_keys):\n",
    "    input_data += [np.load(os.path.join(data_path,key+'_image.npy'))]\n",
    "    try:\n",
    "        gt_data += [np.load(os.path.join(gt_seg_path,key+'_seg.npy'))]\n",
    "    except:\n",
    "        gt_data += [np.zeros_like(input_data[-1])]\n",
    "            \n",
    "# Save pred data\n",
    "print('Retreiving predictions')\n",
    "for pred_path in pred_seg_paths:\n",
    "    for key in tqdm(successful_keys):\n",
    "        pred_data[pred_path] += [np.argmax(np.load(os.path.join(pred_path,key+'_seg.npy')),-1)]\n",
    "\n",
    "# Load config yaml\n",
    "with open(config_file, \"r\") as cf:\n",
    "    config = yaml.safe_load(cf)\n",
    "\n",
    "print('Lengths of input, ground truth, and all predicted data:',len(input_data),len(gt_data),[len(data) for data in pred_data.values()])\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images, gt masks, and predictions to the same size\n",
    "for key_ind in tqdm(range(len(input_data))):\n",
    "    input_data[key_ind] = custom_preproc_op(input_data[key_ind], img_size_r, img_size_c)\n",
    "    gt_data[key_ind] = custom_preproc_op(gt_data[key_ind], img_size_r, img_size_c, order=0)\n",
    "    for pred_name in pred_seg_paths: pred_data[pred_name][key_ind] = custom_preproc_op(pred_data[pred_name][key_ind], img_size_r, img_size_c, order=0)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute quantitative metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute macro 3d dice coefficient\n",
    "label_dict = {v: k for k, v in config['label_mapping'].items()}\n",
    "dice_3d = {(w,label_dict[c]):[] for w in pred_data.keys() for c in range(1,config['num_classes'])}\n",
    "\n",
    "for weak_seg_type,weak_seg_masks in pred_data.items():\n",
    "    for class_ind in range(1,config['num_classes']):\n",
    "        for ind, weak_seg_mask in enumerate(weak_seg_masks):\n",
    "            dice_3d[weak_seg_type,label_dict[class_ind]] += [compute_dice(gt_data[ind]==class_ind, weak_seg_mask==class_ind)] \n",
    "                    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print all DICE scores\n",
    "print('Segmentation scores:')\n",
    "for k, v in dice_3d.items():\n",
    "    print('\\nPredictions:',k[0])\n",
    "    print('Class:',k[1])\n",
    "    print('\\t 3D mean, median dice:',np.around(np.mean(v),3),np.around(np.median(v),3))\n",
    "    print('\\t 3D std dice:',np.around(np.std(v),3))\n",
    "    print('\\t 3D min, max dice:',np.around(np.min(v),3),np.around(np.max(v),3))\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dice histogram\n",
    "\n",
    "for task_class, dice_scores in dice_3d.items():\n",
    "    \n",
    "    dice3d_df = pd.DataFrame.from_dict({'Dice':dice_scores})\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    \n",
    "    dice_hist = sns.histplot(data=dice3d_df, x='Dice')\n",
    "    dice_hist.set_xlabel(\"Dice\",fontsize=14)\n",
    "    dice_hist.set_ylabel(\"Count\",fontsize=14)\n",
    "    dice_hist.set_xlim(0,1)\n",
    "    dice_hist.set_title(k)\n",
    "    dice_hist.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some example results that achieve min, median, and max Dice scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for task_class, all_dice_scores in dice_3d.items():\n",
    "    print('\\nPredictions:',task_class[0])\n",
    "    print('Class:',task_class[1])\n",
    "    \n",
    "    sorted_dice = sorted(all_dice_scores)\n",
    "    sorted_inds = [ind for _, ind in sorted(zip(all_dice_scores,range(len(all_dice_scores))))]\n",
    "\n",
    "    num_per = 3\n",
    "    min_ind = sorted_inds[0:num_per]\n",
    "    max_ind = sorted_inds[-num_per:]\n",
    "    med_ind = sorted_inds[len(sorted_inds)//2-num_per//2:len(sorted_inds)//2+(num_per-num_per//2)+1]\n",
    "\n",
    "    for img_ind, img_id in zip(min_ind+max_ind+med_ind,['Min Dice']*len(min_ind) + ['Max Dice']*len(max_ind) + ['Median Dice']*len(med_ind)):\n",
    "\n",
    "        pred = pred_data[task_class[0]][img_ind] == config['label_mapping'][task_class[1]]\n",
    "        gt = gt_data[img_ind] == config['label_mapping'][task_class[1]]\n",
    "        tps = np.logical_and(pred==1, gt==1)\n",
    "        fns = np.logical_and(pred==0, gt==1)\n",
    "        fps = np.logical_and(pred==1, gt==0)\n",
    "\n",
    "        img_key = successful_keys[img_ind]\n",
    "        plot_classes(input_data[img_ind],tps,fps,fns,size=10,title=(' ').join([img_id,img_key,'Dice='+str(np.around(all_dice_scores[img_ind],3))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medallionEnv",
   "language": "python",
   "name": "medallionenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
